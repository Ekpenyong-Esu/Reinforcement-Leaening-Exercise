{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxKluo348GnC9oxjIt/ex1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekpenyong-Esu/Reinforcement-Leaening-Exercise/blob/main/01RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf          # import tensorflow\n",
        "import numpy as np                # import numpy\n",
        "from tensorflow import keras       #import keras\n"
      ],
      "metadata": {
        "id": "Jq76s5WqHu0P"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 200        # how many time to run the model\n",
        "BATCH_SIZE = 128    # number of item fed to the network at a single EPOCH\n",
        "VERBOSE = 1         # Means not too much details\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128        # Number of output or neuron\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION"
      ],
      "metadata": {
        "id": "4kVliv7jGy-S"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist              # How to load the mnist Datasets\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() # split to X_test and Y_train \n",
        "print(X_train.shape[0], 'train samples') # X_train = 60,000 sample\n",
        "print(X_test.shape[0], 'test samples')    #Y_train = 10,000 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMenZ6RRH5iC",
        "outputId": "2ae0b27a-3c4b-43ec-d5ef-1d1bedad09db"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_image = X_train[0]\n",
        "single_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjnWlzyHNh3R",
        "outputId": "f1207d02-3306-41d4-ecda-d695a1923975"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(dpi=150)\n",
        "plt.imshow(single_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "TX3PK_4BOgls",
        "outputId": "28f70224-8fe6-42b1-9270-285e414ea7ec"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2432623550>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#it is an image With RGb value of 0 to 255. Hence we normalize by dividing it by 255\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "metadata": {
        "id": "CXuA0LHgIDZM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "Yj0aWcvPW6zJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "Y_train = to_categorical(Y_train).astype('float32')\n",
        "Y_test = to_categorical(Y_test).astype('float32')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_8YCqUGfIMoD"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "   \t\tinput_shape=(RESHAPED,),\n",
        "   \t\tname='dense_layer', activation='softmax'))"
      ],
      "metadata": {
        "id": "lbg7WO7eIdvK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geoJh5IkIijv",
        "outputId": "407504cc-ed80-4f2a-f756-be282d9bf962"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YOqRwN-cIpa1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT) # note that percentage of the data is kept for vallidation and\n",
        "                                                        # is called validation split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr-_h7CxIvQo",
        "outputId": "42713565-28b0-44f4-a47e-2275dc4413fc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3725 - accuracy: 0.6606 - val_loss: 0.8929 - val_accuracy: 0.8278\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7934 - accuracy: 0.8284 - val_loss: 0.6558 - val_accuracy: 0.8592\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6437 - accuracy: 0.8511 - val_loss: 0.5608 - val_accuracy: 0.8703\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.8623 - val_loss: 0.5078 - val_accuracy: 0.8786\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5270 - accuracy: 0.8688 - val_loss: 0.4739 - val_accuracy: 0.8831\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.8742 - val_loss: 0.4499 - val_accuracy: 0.8878\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4742 - accuracy: 0.8786 - val_loss: 0.4319 - val_accuracy: 0.8907\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8821 - val_loss: 0.4179 - val_accuracy: 0.8928\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4428 - accuracy: 0.8842 - val_loss: 0.4062 - val_accuracy: 0.8953\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8861 - val_loss: 0.3967 - val_accuracy: 0.8972\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4213 - accuracy: 0.8881 - val_loss: 0.3888 - val_accuracy: 0.8982\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - accuracy: 0.8902 - val_loss: 0.3818 - val_accuracy: 0.8996\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - accuracy: 0.8917 - val_loss: 0.3757 - val_accuracy: 0.9002\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8927 - val_loss: 0.3703 - val_accuracy: 0.9011\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.8939 - val_loss: 0.3656 - val_accuracy: 0.9018\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8951 - val_loss: 0.3613 - val_accuracy: 0.9032\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8962 - val_loss: 0.3576 - val_accuracy: 0.9036\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3791 - accuracy: 0.8973 - val_loss: 0.3541 - val_accuracy: 0.9040\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8973 - val_loss: 0.3507 - val_accuracy: 0.9050\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8985 - val_loss: 0.3478 - val_accuracy: 0.9058\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8990 - val_loss: 0.3450 - val_accuracy: 0.9072\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3652 - accuracy: 0.8997 - val_loss: 0.3425 - val_accuracy: 0.9069\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3623 - accuracy: 0.9002 - val_loss: 0.3401 - val_accuracy: 0.9074\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.9003 - val_loss: 0.3380 - val_accuracy: 0.9078\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.9011 - val_loss: 0.3359 - val_accuracy: 0.9084\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.9018 - val_loss: 0.3339 - val_accuracy: 0.9087\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3524 - accuracy: 0.9022 - val_loss: 0.3321 - val_accuracy: 0.9091\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.9028 - val_loss: 0.3305 - val_accuracy: 0.9091\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.9031 - val_loss: 0.3287 - val_accuracy: 0.9091\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.9038 - val_loss: 0.3272 - val_accuracy: 0.9097\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.9040 - val_loss: 0.3258 - val_accuracy: 0.9104\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.9046 - val_loss: 0.3244 - val_accuracy: 0.9101\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.9049 - val_loss: 0.3230 - val_accuracy: 0.9104\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3396 - accuracy: 0.9052 - val_loss: 0.3217 - val_accuracy: 0.9111\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.9057 - val_loss: 0.3207 - val_accuracy: 0.9111\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.9060 - val_loss: 0.3195 - val_accuracy: 0.9119\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.9067 - val_loss: 0.3183 - val_accuracy: 0.9112\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.9068 - val_loss: 0.3173 - val_accuracy: 0.9121\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.9071 - val_loss: 0.3163 - val_accuracy: 0.9118\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.9074 - val_loss: 0.3153 - val_accuracy: 0.9123\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.9078 - val_loss: 0.3143 - val_accuracy: 0.9128\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.9082 - val_loss: 0.3134 - val_accuracy: 0.9126\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.9087 - val_loss: 0.3125 - val_accuracy: 0.9131\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.9088 - val_loss: 0.3117 - val_accuracy: 0.9128\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.9092 - val_loss: 0.3109 - val_accuracy: 0.9133\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.9094 - val_loss: 0.3101 - val_accuracy: 0.9139\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.9096 - val_loss: 0.3094 - val_accuracy: 0.9143\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.9102 - val_loss: 0.3087 - val_accuracy: 0.9144\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3221 - accuracy: 0.9104 - val_loss: 0.3079 - val_accuracy: 0.9145\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.9107 - val_loss: 0.3073 - val_accuracy: 0.9146\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.9109 - val_loss: 0.3065 - val_accuracy: 0.9149\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.9110 - val_loss: 0.3059 - val_accuracy: 0.9154\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3187 - accuracy: 0.9115 - val_loss: 0.3054 - val_accuracy: 0.9155\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3179 - accuracy: 0.9116 - val_loss: 0.3047 - val_accuracy: 0.9153\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.9119 - val_loss: 0.3040 - val_accuracy: 0.9155\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.9122 - val_loss: 0.3035 - val_accuracy: 0.9158\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3157 - accuracy: 0.9123 - val_loss: 0.3029 - val_accuracy: 0.9158\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.9126 - val_loss: 0.3024 - val_accuracy: 0.9163\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3143 - accuracy: 0.9127 - val_loss: 0.3018 - val_accuracy: 0.9159\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3136 - accuracy: 0.9133 - val_loss: 0.3014 - val_accuracy: 0.9162\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3130 - accuracy: 0.9132 - val_loss: 0.3008 - val_accuracy: 0.9168\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3123 - accuracy: 0.9136 - val_loss: 0.3004 - val_accuracy: 0.9168\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3117 - accuracy: 0.9137 - val_loss: 0.2999 - val_accuracy: 0.9167\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3111 - accuracy: 0.9137 - val_loss: 0.2994 - val_accuracy: 0.9166\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3105 - accuracy: 0.9141 - val_loss: 0.2989 - val_accuracy: 0.9172\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.9142 - val_loss: 0.2985 - val_accuracy: 0.9172\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.9146 - val_loss: 0.2981 - val_accuracy: 0.9172\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3088 - accuracy: 0.9145 - val_loss: 0.2977 - val_accuracy: 0.9177\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3082 - accuracy: 0.9146 - val_loss: 0.2973 - val_accuracy: 0.9169\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3077 - accuracy: 0.9149 - val_loss: 0.2969 - val_accuracy: 0.9178\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3072 - accuracy: 0.9153 - val_loss: 0.2964 - val_accuracy: 0.9182\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.9154 - val_loss: 0.2960 - val_accuracy: 0.9179\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3062 - accuracy: 0.9151 - val_loss: 0.2957 - val_accuracy: 0.9181\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3057 - accuracy: 0.9156 - val_loss: 0.2953 - val_accuracy: 0.9181\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.9154 - val_loss: 0.2950 - val_accuracy: 0.9181\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.9157 - val_loss: 0.2947 - val_accuracy: 0.9185\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3042 - accuracy: 0.9156 - val_loss: 0.2942 - val_accuracy: 0.9187\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.9161 - val_loss: 0.2939 - val_accuracy: 0.9184\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3033 - accuracy: 0.9161 - val_loss: 0.2935 - val_accuracy: 0.9184\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.9160 - val_loss: 0.2933 - val_accuracy: 0.9189\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3024 - accuracy: 0.9162 - val_loss: 0.2929 - val_accuracy: 0.9188\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.9165 - val_loss: 0.2927 - val_accuracy: 0.9191\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3016 - accuracy: 0.9166 - val_loss: 0.2924 - val_accuracy: 0.9190\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3012 - accuracy: 0.9167 - val_loss: 0.2921 - val_accuracy: 0.9192\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3008 - accuracy: 0.9169 - val_loss: 0.2918 - val_accuracy: 0.9189\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.9166 - val_loss: 0.2914 - val_accuracy: 0.9192\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.9171 - val_loss: 0.2912 - val_accuracy: 0.9191\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2996 - accuracy: 0.9171 - val_loss: 0.2909 - val_accuracy: 0.9191\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.9169 - val_loss: 0.2906 - val_accuracy: 0.9188\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.9172 - val_loss: 0.2904 - val_accuracy: 0.9192\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.9173 - val_loss: 0.2901 - val_accuracy: 0.9192\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.9174 - val_loss: 0.2899 - val_accuracy: 0.9190\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.9175 - val_loss: 0.2897 - val_accuracy: 0.9189\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.9176 - val_loss: 0.2893 - val_accuracy: 0.9193\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.9174 - val_loss: 0.2891 - val_accuracy: 0.9194\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2967 - accuracy: 0.9175 - val_loss: 0.2889 - val_accuracy: 0.9193\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9178 - val_loss: 0.2885 - val_accuracy: 0.9196\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9178 - val_loss: 0.2883 - val_accuracy: 0.9197\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.9178 - val_loss: 0.2881 - val_accuracy: 0.9200\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2954 - accuracy: 0.9181 - val_loss: 0.2879 - val_accuracy: 0.9196\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2951 - accuracy: 0.9181 - val_loss: 0.2877 - val_accuracy: 0.9197\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9181 - val_loss: 0.2874 - val_accuracy: 0.9200\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.9180 - val_loss: 0.2873 - val_accuracy: 0.9203\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.9183 - val_loss: 0.2871 - val_accuracy: 0.9201\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.9183 - val_loss: 0.2869 - val_accuracy: 0.9202\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.9182 - val_loss: 0.2866 - val_accuracy: 0.9203\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9184 - val_loss: 0.2864 - val_accuracy: 0.9202\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.9186 - val_loss: 0.2862 - val_accuracy: 0.9202\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2928 - accuracy: 0.9185 - val_loss: 0.2860 - val_accuracy: 0.9201\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2925 - accuracy: 0.9187 - val_loss: 0.2858 - val_accuracy: 0.9202\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2922 - accuracy: 0.9186 - val_loss: 0.2856 - val_accuracy: 0.9205\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.9186 - val_loss: 0.2854 - val_accuracy: 0.9207\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.9189 - val_loss: 0.2853 - val_accuracy: 0.9208\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9187 - val_loss: 0.2850 - val_accuracy: 0.9208\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.9193 - val_loss: 0.2849 - val_accuracy: 0.9208\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2909 - accuracy: 0.9190 - val_loss: 0.2847 - val_accuracy: 0.9212\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.9191 - val_loss: 0.2845 - val_accuracy: 0.9207\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.9192 - val_loss: 0.2844 - val_accuracy: 0.9212\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.9194 - val_loss: 0.2842 - val_accuracy: 0.9208\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2899 - accuracy: 0.9194 - val_loss: 0.2841 - val_accuracy: 0.9210\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.9195 - val_loss: 0.2839 - val_accuracy: 0.9211\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.9193 - val_loss: 0.2837 - val_accuracy: 0.9211\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9194 - val_loss: 0.2836 - val_accuracy: 0.9211\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.9193 - val_loss: 0.2834 - val_accuracy: 0.9213\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.9198 - val_loss: 0.2833 - val_accuracy: 0.9210\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2884 - accuracy: 0.9196 - val_loss: 0.2831 - val_accuracy: 0.9210\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9194 - val_loss: 0.2830 - val_accuracy: 0.9211\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.9198 - val_loss: 0.2827 - val_accuracy: 0.9210\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.9201 - val_loss: 0.2827 - val_accuracy: 0.9209\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.9202 - val_loss: 0.2826 - val_accuracy: 0.9210\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2873 - accuracy: 0.9200 - val_loss: 0.2824 - val_accuracy: 0.9215\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2871 - accuracy: 0.9203 - val_loss: 0.2822 - val_accuracy: 0.9212\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9204 - val_loss: 0.2821 - val_accuracy: 0.9215\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.9204 - val_loss: 0.2821 - val_accuracy: 0.9214\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2865 - accuracy: 0.9203 - val_loss: 0.2818 - val_accuracy: 0.9215\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.9205 - val_loss: 0.2817 - val_accuracy: 0.9218\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9206 - val_loss: 0.2815 - val_accuracy: 0.9217\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2858 - accuracy: 0.9203 - val_loss: 0.2814 - val_accuracy: 0.9217\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.9208 - val_loss: 0.2813 - val_accuracy: 0.9212\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9207 - val_loss: 0.2811 - val_accuracy: 0.9216\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.9206 - val_loss: 0.2810 - val_accuracy: 0.9221\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9207 - val_loss: 0.2810 - val_accuracy: 0.9215\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9208 - val_loss: 0.2808 - val_accuracy: 0.9217\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.9206 - val_loss: 0.2807 - val_accuracy: 0.9221\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.9210 - val_loss: 0.2805 - val_accuracy: 0.9218\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9209 - val_loss: 0.2804 - val_accuracy: 0.9224\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.9213 - val_loss: 0.2803 - val_accuracy: 0.9218\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9211 - val_loss: 0.2801 - val_accuracy: 0.9219\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9210 - val_loss: 0.2800 - val_accuracy: 0.9223\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9211 - val_loss: 0.2799 - val_accuracy: 0.9222\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.9214 - val_loss: 0.2798 - val_accuracy: 0.9218\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9215 - val_loss: 0.2798 - val_accuracy: 0.9220\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2831 - accuracy: 0.9215 - val_loss: 0.2796 - val_accuracy: 0.9222\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9216 - val_loss: 0.2795 - val_accuracy: 0.9222\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9215 - val_loss: 0.2794 - val_accuracy: 0.9221\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2825 - accuracy: 0.9216 - val_loss: 0.2793 - val_accuracy: 0.9223\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9215 - val_loss: 0.2792 - val_accuracy: 0.9224\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9217 - val_loss: 0.2791 - val_accuracy: 0.9224\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.9217 - val_loss: 0.2789 - val_accuracy: 0.9223\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.9220 - val_loss: 0.2789 - val_accuracy: 0.9225\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9218 - val_loss: 0.2788 - val_accuracy: 0.9228\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.9218 - val_loss: 0.2787 - val_accuracy: 0.9222\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.9220 - val_loss: 0.2785 - val_accuracy: 0.9224\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9218 - val_loss: 0.2785 - val_accuracy: 0.9224\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.9219 - val_loss: 0.2784 - val_accuracy: 0.9229\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9222 - val_loss: 0.2783 - val_accuracy: 0.9226\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9220 - val_loss: 0.2781 - val_accuracy: 0.9227\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.9223 - val_loss: 0.2781 - val_accuracy: 0.9229\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.9221 - val_loss: 0.2780 - val_accuracy: 0.9234\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.9224 - val_loss: 0.2779 - val_accuracy: 0.9227\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.9222 - val_loss: 0.2778 - val_accuracy: 0.9236\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2800 - accuracy: 0.9224 - val_loss: 0.2778 - val_accuracy: 0.9228\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9225 - val_loss: 0.2777 - val_accuracy: 0.9231\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.9225 - val_loss: 0.2775 - val_accuracy: 0.9235\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2795 - accuracy: 0.9225 - val_loss: 0.2775 - val_accuracy: 0.9232\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.9224 - val_loss: 0.2773 - val_accuracy: 0.9233\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9228 - val_loss: 0.2773 - val_accuracy: 0.9233\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9228 - val_loss: 0.2772 - val_accuracy: 0.9234\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.9225 - val_loss: 0.2771 - val_accuracy: 0.9234\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2789 - accuracy: 0.9225 - val_loss: 0.2770 - val_accuracy: 0.9233\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.9226 - val_loss: 0.2769 - val_accuracy: 0.9232\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2786 - accuracy: 0.9229 - val_loss: 0.2768 - val_accuracy: 0.9234\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2784 - accuracy: 0.9228 - val_loss: 0.2769 - val_accuracy: 0.9235\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2783 - accuracy: 0.9231 - val_loss: 0.2767 - val_accuracy: 0.9238\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2782 - accuracy: 0.9229 - val_loss: 0.2767 - val_accuracy: 0.9239\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2780 - accuracy: 0.9228 - val_loss: 0.2766 - val_accuracy: 0.9230\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2779 - accuracy: 0.9231 - val_loss: 0.2765 - val_accuracy: 0.9235\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9232 - val_loss: 0.2763 - val_accuracy: 0.9237\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9230 - val_loss: 0.2763 - val_accuracy: 0.9240\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2775 - accuracy: 0.9232 - val_loss: 0.2763 - val_accuracy: 0.9235\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9231 - val_loss: 0.2762 - val_accuracy: 0.9236\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2772 - accuracy: 0.9231 - val_loss: 0.2761 - val_accuracy: 0.9236\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2771 - accuracy: 0.9233 - val_loss: 0.2760 - val_accuracy: 0.9237\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2770 - accuracy: 0.9234 - val_loss: 0.2759 - val_accuracy: 0.9236\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2769 - accuracy: 0.9233 - val_loss: 0.2759 - val_accuracy: 0.9242\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.9232 - val_loss: 0.2758 - val_accuracy: 0.9241\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2766 - accuracy: 0.9233 - val_loss: 0.2757 - val_accuracy: 0.9241\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2765 - accuracy: 0.9231 - val_loss: 0.2757 - val_accuracy: 0.9237\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2764 - accuracy: 0.9235 - val_loss: 0.2755 - val_accuracy: 0.9243\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2763 - accuracy: 0.9234 - val_loss: 0.2755 - val_accuracy: 0.9240\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2432593dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBy1Pzh2GqNI",
        "outputId": "663c050a-6d85-48f1-c250-1321d478c9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9226\n",
            "Test accuracy: 0.9225999712944031\n",
            "313/313 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# making prediction\n",
        "predictions = model.predict(X_test)\n"
      ]
    }
  ]
}