{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8HVlEL3IlB3nZIp/IXPIh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, regularizers, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        " \n",
        "EPOCHS=50\n",
        "NUM_CLASSES = 10\n",
        "    \n",
        "\n",
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "    x_train = x_train/255\n",
        "    x_test = x_test/255\n",
        " \n",
        "    #normalize \n",
        "    #mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "    #std = np.std(x_train,axis=(0,1,2,3))\n",
        "    #x_train = (x_train-mean)/(std+1e-7)\n",
        "    #x_test = (x_test-mean)/(std+1e-7)\n",
        " \n",
        "    y_train =  tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
        "    y_test =  tf.keras.utils.to_categorical(y_test,NUM_CLASSES)\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def build_model(): \n",
        "    model = models.Sequential()\n",
        "    \n",
        "    #1st blocl\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', \n",
        "        input_shape=x_train.shape[1:], activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    #2nd block\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    #3d block \n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.4))\n",
        "\n",
        "    #dense  \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "    model.summary()\n",
        " \n",
        "\n",
        "(x_train, y_train, x_test, y_test) = load_data()\n",
        "model = build_model()\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "            optimizer='RMSprop', \n",
        "            metrics=['accuracy'])\n",
        "\n",
        "#image augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        " \n",
        "#train\n",
        "batch_size = 64\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "#save to disk\n",
        "model_json = model.to_json()\n",
        "with open('model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights('model.h5') \n",
        "\n",
        "#test\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaYedVihVAHH",
        "outputId": "3057fc89-bf82-4b78-dddd-a526236b83f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-2236a13b2652>:79: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 30s 36ms/step - loss: 2.0740 - accuracy: 0.3753 - val_loss: 8.6824 - val_accuracy: 0.2872\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 1.6293 - accuracy: 0.4965 - val_loss: 1.2350 - val_accuracy: 0.5741\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 1.4483 - accuracy: 0.5405 - val_loss: 1.2450 - val_accuracy: 0.5881\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 29s 36ms/step - loss: 1.2727 - accuracy: 0.5856 - val_loss: 1.0598 - val_accuracy: 0.6556\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 29s 36ms/step - loss: 1.1641 - accuracy: 0.6163 - val_loss: 1.2333 - val_accuracy: 0.6067\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 1.0781 - accuracy: 0.6361 - val_loss: 1.0539 - val_accuracy: 0.6727\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 1.0140 - accuracy: 0.6528 - val_loss: 1.1567 - val_accuracy: 0.6503\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.9616 - accuracy: 0.6730 - val_loss: 1.1879 - val_accuracy: 0.6594\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.9121 - accuracy: 0.6892 - val_loss: 1.1456 - val_accuracy: 0.6551\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.8811 - accuracy: 0.6978 - val_loss: 0.8957 - val_accuracy: 0.7119\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.8538 - accuracy: 0.7040 - val_loss: 0.9090 - val_accuracy: 0.7104\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.8277 - accuracy: 0.7170 - val_loss: 0.7003 - val_accuracy: 0.7646\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.8058 - accuracy: 0.7214 - val_loss: 0.7699 - val_accuracy: 0.7521\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.7898 - accuracy: 0.7277 - val_loss: 1.0269 - val_accuracy: 0.6905\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.7692 - accuracy: 0.7354 - val_loss: 0.8049 - val_accuracy: 0.7392\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.7557 - accuracy: 0.7380 - val_loss: 0.7601 - val_accuracy: 0.7568\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.7407 - accuracy: 0.7468 - val_loss: 0.7545 - val_accuracy: 0.7556\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.7302 - accuracy: 0.7480 - val_loss: 0.6998 - val_accuracy: 0.7728\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.7153 - accuracy: 0.7528 - val_loss: 0.6887 - val_accuracy: 0.7771\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.7001 - accuracy: 0.7582 - val_loss: 0.7046 - val_accuracy: 0.7750\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.6891 - accuracy: 0.7608 - val_loss: 0.6508 - val_accuracy: 0.7961\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6798 - accuracy: 0.7658 - val_loss: 0.6601 - val_accuracy: 0.7840\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.6723 - accuracy: 0.7680 - val_loss: 0.6215 - val_accuracy: 0.7926\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.6698 - accuracy: 0.7703 - val_loss: 0.6987 - val_accuracy: 0.7831\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.6595 - accuracy: 0.7738 - val_loss: 0.6214 - val_accuracy: 0.8009\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6518 - accuracy: 0.7765 - val_loss: 0.6049 - val_accuracy: 0.8019\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.6448 - accuracy: 0.7801 - val_loss: 0.6968 - val_accuracy: 0.7792\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.6361 - accuracy: 0.7791 - val_loss: 0.6635 - val_accuracy: 0.7821\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.6357 - accuracy: 0.7801 - val_loss: 0.6323 - val_accuracy: 0.7996\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.6363 - accuracy: 0.7802 - val_loss: 0.5976 - val_accuracy: 0.8033\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6227 - accuracy: 0.7841 - val_loss: 0.7069 - val_accuracy: 0.7803\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6108 - accuracy: 0.7897 - val_loss: 0.6100 - val_accuracy: 0.8012\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6138 - accuracy: 0.7878 - val_loss: 0.6791 - val_accuracy: 0.7845\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6091 - accuracy: 0.7911 - val_loss: 0.5915 - val_accuracy: 0.8104\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6047 - accuracy: 0.7919 - val_loss: 0.6696 - val_accuracy: 0.7877\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.6028 - accuracy: 0.7908 - val_loss: 0.6250 - val_accuracy: 0.8049\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5951 - accuracy: 0.7943 - val_loss: 0.5937 - val_accuracy: 0.8083\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 0.5965 - accuracy: 0.7951 - val_loss: 0.6176 - val_accuracy: 0.8035\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5840 - accuracy: 0.7984 - val_loss: 0.5147 - val_accuracy: 0.8315\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5874 - accuracy: 0.7978 - val_loss: 0.6361 - val_accuracy: 0.8004\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5842 - accuracy: 0.7986 - val_loss: 0.5209 - val_accuracy: 0.8311\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5784 - accuracy: 0.8006 - val_loss: 0.5625 - val_accuracy: 0.8160\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5708 - accuracy: 0.8026 - val_loss: 0.5758 - val_accuracy: 0.8178\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.5712 - accuracy: 0.8059 - val_loss: 0.6711 - val_accuracy: 0.7899\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.5712 - accuracy: 0.8013 - val_loss: 0.5406 - val_accuracy: 0.8295\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.5692 - accuracy: 0.8033 - val_loss: 0.7750 - val_accuracy: 0.7628\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5626 - accuracy: 0.8074 - val_loss: 0.5405 - val_accuracy: 0.8271\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5572 - accuracy: 0.8086 - val_loss: 0.6432 - val_accuracy: 0.8016\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5590 - accuracy: 0.8077 - val_loss: 0.6207 - val_accuracy: 0.8009\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.5577 - accuracy: 0.8088 - val_loss: 0.6063 - val_accuracy: 0.8195\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.6063 - accuracy: 0.8195\n",
            "\n",
            "Test result: 81.950 loss: 0.606\n"
          ]
        }
      ]
    }
  ]
}